---
title: "Test Suite Generation Early Access"
description: "New features to the Speakeasy Platform - August 7, 2024"
keywords:
  [api, openapi, docs, sdk generation, python, devex, dx, developer experience]
image: "/media/changelog-2024-08-07.png"
date: 2024-08-07
authors:
  - name: Nolan Sullivan
  - image_url: "/media/author-headshots/nolan.jpeg"
featured_image: "/media/changelog-2024-08-07.png"
---

import { CodeWithTabs } from "~/components/codehike/CodeTabs";
import { Callout } from "~/components";
import beezy_ide_video from "./assets/beezy-ide.mp4";
import mintlify_setup from "./assets/mintlify.mp4";

<Callout title="Get Access" variant="success">
  If you are interested in participating in early access, please fill out [this
  form](https://speakeasyapi.typeform.com/testing-early), or, if you're an
  existing customer, drop a note in your Speakeasy Slack connect channel.
</Callout>

If at first you don't succeed test, test, test again.

We're excited to announce the early access release of our new Test Generation feature. It empowers developer teams to ship SDKs with confidence that they work as intended for end users.

## Test Generation

<CodeWithTabs>

```typescript !!tabs analysis.test.js
"use strict";

Object.defineProperty(exports, "__esModule", { value: true });
const index_js_1 = require("../index.js");
const vitest_1 = require("vitest");
(0, vitest_1.test)("Analysis Analyze Text", async () => {
    const beezy = new index_js_1.Beezy({
        security: {
            clientID: process.env("BEEZY_CLIENT_ID"),
            clientSecret: process.env("BEEZY_CLIENT_SECRET"),
        },
    });
    const result = await beezy.analysis.analyzeText({
        text: "What is the difference between OpenAPI and Swagger?",
        analysisTypes: ["keywords"],
        model: "ex-7b",
    });
    (0, vitest_1.expect)(result).toEqual({
        results: [
            {
                keywords: ["<value>"],
            },
        ],
    });
});
```

```python !!tabs test_analysis.py
from beezyai import Beezy
from beezyai.models import shared


def test_analysis_analyze_text():
    s = Beezy(
        security=shared.Security(
            client_id="<YOUR_CLIENT_ID_HERE>",
            client_secret="<YOUR_CLIENT_SECRET_HERE>",
        ),
    )

    assert s is not None

    res = s.analysis.analyze_text(request={
        "text": "What is the difference between OpenAPI and Swagger?",
        "analysis_types": [
            shared.AnalysisTypes.KEYWORDS,
        ],
        "model": shared.Model.EX_7B,
    })

    assert res is not None
    assert res is not None
    assert res == shared.TextAnalysisResponse(
        results=[
            shared.KeywordAnalysis(
                keywords=[
                    "<value>",
                ],
            ),
        ],
    )
```

```go !!tabs analysis_test.go
package tests

import (
	"beezyai"
	"beezyai/models/shared"
	"context"
	"github.com/stretchr/testify/assert"
	"github.com/stretchr/testify/require"
	"testing"
)

func TestAnalysis_AnalyzeText(t *testing.T) {
	s := beezyai.New(
		beezyai.WithSecurity(shared.Security{
			ClientID:     "<YOUR_CLIENT_ID_HERE>",
			ClientSecret: "<YOUR_CLIENT_SECRET_HERE>",
		}),
	)
	var text string = "What is the difference between OpenAPI and Swagger?"

	analysisTypes := []shared.AnalysisTypes{
		shared.AnalysisTypesKeywords,
	}

	var model *shared.Model = shared.ModelEx7b.ToPointer()
	ctx := context.Background()
	res, err := s.Analysis.AnalyzeText(ctx, text, analysisTypes, model)
	require.NoError(t, err)
	require.NotNil(t, res)
	assert.Equal(t, shared.TextAnalysisResponse{
		Results: []shared.Results{
			shared.CreateResultsKeywordAnalysis(
				shared.KeywordAnalysis{
					Keywords: []string{
						"<value>",
					},
				},
			),
		},
	}, *res.TextAnalysisResponse)
}

```

</CodeWithTabs>

### What's Included

- Support for TypeScript, Python, and Go,
- Test creation based on the examples in your OpenAPI spec,
- The ability to specify custom requests and responses for your tests.

### How It Works

1. Specify the examples you want to use in your OpenAPI spec.
2. Optionally specify custom examples via a `tests.yaml`.
3. Speakeasy generates tests for your SDKs based on the examples you provided.

The generated tests will be created in a new `tests` directory in your SDK. For each language, we've selected a popular testing framework for the generated tests:

- TypeScript: [Vitest](https://vitest.dev/)
- Python: [Pytest](https://docs.pytest.org/en/stable/)
- Go: [Testify](https://github.com/stretchr/testify) along with Go's built-in testing package

---

## 🐝 New Features and Bug Fixes 🐛

<Callout title="NOTE" variant="info">
  Based on the most recent CLI version: [**Speakeasy
  v1.353.1**](https://github.com/speakeasy-api/openapi-generation/releases/tag/v1.353.1)
</Callout>

### TypeScript

🐝 Feat: Readme's render with environment variable usage \
🐛 Fix: Updated `.gitignore` rules for TS SDKs

### Python

🐝 Feat: Readme's render with environment variable usage \
🐝 Feat: Added Python debug logger interface \
🐛 Fix: Buffering of streaming responses and TypedDict unmarshalling in pythonv2 \
🐛 Fix: Handle `consts` in non-json

### Go

🐝 Feat: Readme's render with environment variable usage

### Terraform

🐛 Fix: Dependencies upgraded \
🐛 Fix: Prevent creating attribute validators for invalid or RE2 engine incompatible OAS pattern \
🐛 Fix: Support for flattened security env vars

### Java

🐝 Feat: Support for discriminated oneOf

### C#

🐝 Feat: Implemented support for `x-speakeasy-enums`
